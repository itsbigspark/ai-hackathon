{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tombutler/Documents/ai-hackathon\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "from data.processed.pre_process_titanic import pre_process_df\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"data/raw/train.csv\"\n",
    "TEST_DATA_PATH = \"data/raw/test.csv\"\n",
    "FAKE_DATA_PATH = \"data/fake/tabgan_data.csv\"\n",
    "NUM_COLUMNS = [\"Fare\", \"Age\"]\n",
    "CAT_COLUMNS = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"]\n",
    "LABEL = \"Survived\"\n",
    "COLUMNS = NUM_COLUMNS + CAT_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load in the data and prepare it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "train = pre_process_df(TRAIN_DATA_PATH)[COLUMNS]\n",
    "target = pd.read_csv(TRAIN_DATA_PATH)[[LABEL]]\n",
    "test = pre_process_df(TEST_DATA_PATH)[COLUMNS]\n",
    "\n",
    "fake = pd.read_csv(FAKE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "train = pd.DataFrame(imputer.fit_transform(train), columns=COLUMNS)\n",
    "test = pd.DataFrame(imputer.fit_transform(test), columns=COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract a test set, and set up the real and fake features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train[COLUMNS].copy()\n",
    "y = target.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_real, X_test, y_train_real, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_fake = fake[COLUMNS].copy()\n",
    "y_train_fake = fake[LABEL].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qm/y349637s1v91yky4ss3rlmn80000gn/T/ipykernel_59737/3585395417.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model_real.fit(X_train_real, y_train_real)\n"
     ]
    }
   ],
   "source": [
    "model_real = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model_real.fit(X_train_real, y_train_real)\n",
    "predictions_real = model_real.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_fake = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model_fake.fit(X_train_fake, y_train_fake)\n",
    "predictions_fake = model_fake.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compare the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_test, predictions):\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tombutler/miniforge3/envs/jupyter-lab/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "metrics_real = get_metrics(y_test, predictions_real)\n",
    "metrics_fake = get_metrics(y_test, predictions_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.820627802690583,\n",
       " 'precision': 0.896551724137931,\n",
       " 'recall': 0.6046511627906976}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6143497757847534, 'precision': 0.0, 'recall': 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "Precision: 0.70\n",
      "Recall: 0.49\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:,.2f}\")\n",
    "print(f\"Precision: {precision:,.2f}\")\n",
    "print(f\"Recall: {recall:,.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
